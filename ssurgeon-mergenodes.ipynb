{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Testing the AddEdge Class in Stanford CoreNLP's Ssurgeon Library\n# Stanford CoreNLP is a suite of natural language processing tools that provide functionalities such as tokenization, part-of-speech tagging, parsing, and more.\n# Ssurgeon (Semantic Surgeon) is a component within Stanford CoreNLP that allows users to perform complex manipulations on the dependency graphs generated by the parser.\n# MergeNode is a class within Ssurgeon designed to combines two words into one word\n# This requires one of the nodes to be the head of a phrase of the words, and the dependent words can't have any extra edges in or out of that subgraph\n# The word and lemma will be the combination of the words, squished together. Before and after will be updated to use the before and after of the endpoints of the subgraph","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-17T15:39:21.032961Z","iopub.execute_input":"2024-10-17T15:39:21.034215Z","iopub.status.idle":"2024-10-17T15:39:22.352425Z","shell.execute_reply.started":"2024-10-17T15:39:21.034160Z","shell.execute_reply":"2024-10-17T15:39:22.350896Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Two versions of the code are provided:\n# First Version (SsurgeonMergeNodesComparison.java): Attempts to use Ssurgeon and compare it with manual merge.\n# Second Version (SsurgeonMergeNodes.java): Introduces a variation by adding a POS tag as an attributes to guide the merge operation.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install Java\n!apt-get update\n!apt-get install -y openjdk-11-jdk-headless\n!java -version\n\n# Download Stanford CoreNLP\n# Download Stanford CoreNLP 4.5.5\n!wget https://nlp.stanford.edu/software/stanford-corenlp-4.5.5.zip\n!unzip stanford-corenlp-4.5.5.zip","metadata":{"execution":{"iopub.status.busy":"2024-10-17T15:39:22.355122Z","iopub.execute_input":"2024-10-17T15:39:22.355920Z","iopub.status.idle":"2024-10-17T15:41:25.367036Z","shell.execute_reply.started":"2024-10-17T15:39:22.355858Z","shell.execute_reply":"2024-10-17T15:41:25.365462Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Get:1 https://packages.cloud.google.com/apt gcsfuse-focal InRelease [1227 B]\nHit:2 http://archive.ubuntu.com/ubuntu focal InRelease                         \nGet:3 http://security.ubuntu.com/ubuntu focal-security InRelease [128 kB]      \nGet:4 https://packages.cloud.google.com/apt cloud-sdk InRelease [1618 B]       \nGet:5 http://archive.ubuntu.com/ubuntu focal-updates InRelease [128 kB]        \nGet:6 https://packages.cloud.google.com/apt gcsfuse-focal/main amd64 Packages [28.6 kB]\nGet:7 https://packages.cloud.google.com/apt cloud-sdk/main amd64 Packages [3339 kB]\nGet:8 https://packages.cloud.google.com/apt cloud-sdk/main all Packages [1552 kB]\nGet:9 http://archive.ubuntu.com/ubuntu focal-backports InRelease [128 kB]     \nGet:10 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [4090 kB]\nGet:11 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [4532 kB]\nGet:12 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1274 kB]\nGet:13 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1566 kB]\nGet:14 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [4069 kB]\nGet:15 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [4242 kB]\nFetched 25.1 MB in 3s (7738 kB/s)                                              \nReading package lists... Done\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nSuggested packages:\n  openjdk-11-demo openjdk-11-source\nThe following NEW packages will be installed:\n  openjdk-11-jdk-headless\n0 upgraded, 1 newly installed, 0 to remove and 52 not upgraded.\nNeed to get 73.7 MB of archives.\nAfter this operation, 82.0 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 openjdk-11-jdk-headless amd64 11.0.24+8-1ubuntu3~20.04 [73.7 MB]\nFetched 73.7 MB in 2s (30.8 MB/s)                  \nSelecting previously unselected package openjdk-11-jdk-headless:amd64.\n(Reading database ... 115958 files and directories currently installed.)\nPreparing to unpack .../openjdk-11-jdk-headless_11.0.24+8-1ubuntu3~20.04_amd64.deb ...\nUnpacking openjdk-11-jdk-headless:amd64 (11.0.24+8-1ubuntu3~20.04) ...\nSetting up openjdk-11-jdk-headless:amd64 (11.0.24+8-1ubuntu3~20.04) ...\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmic to provide /usr/bin/rmic (rmic) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jaotc to provide /usr/bin/jaotc (jaotc) in auto mode\nupdate-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\nopenjdk version \"11.0.24\" 2024-07-16\nOpenJDK Runtime Environment (build 11.0.24+8-post-Ubuntu-1ubuntu320.04)\nOpenJDK 64-Bit Server VM (build 11.0.24+8-post-Ubuntu-1ubuntu320.04, mixed mode, sharing)\n--2024-10-17 15:39:48--  https://nlp.stanford.edu/software/stanford-corenlp-4.5.5.zip\nResolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\nConnecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\nHTTP request sent, awaiting response... 302 FOUND\nLocation: https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-4.5.5.zip [following]\n--2024-10-17 15:39:48--  https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-4.5.5.zip\nResolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\nConnecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 505626302 (482M) [application/zip]\nSaving to: 'stanford-corenlp-4.5.5.zip'\n\nstanford-corenlp-4. 100%[===================>] 482.20M  5.07MB/s    in 92s     \n\n2024-10-17 15:41:20 (5.26 MB/s) - 'stanford-corenlp-4.5.5.zip' saved [505626302/505626302]\n\nArchive:  stanford-corenlp-4.5.5.zip\n   creating: stanford-corenlp-4.5.5/\n  inflating: stanford-corenlp-4.5.5/javax.activation-api-1.2.0.jar  \n  inflating: stanford-corenlp-4.5.5/Makefile  \n   creating: stanford-corenlp-4.5.5/sutime/\n  inflating: stanford-corenlp-4.5.5/sutime/spanish.sutime.txt  \n  inflating: stanford-corenlp-4.5.5/sutime/english.holidays.sutime.txt  \n  inflating: stanford-corenlp-4.5.5/sutime/defs.sutime.txt  \n  inflating: stanford-corenlp-4.5.5/sutime/english.sutime.txt  \n  inflating: stanford-corenlp-4.5.5/sutime/british.sutime.txt  \n  inflating: stanford-corenlp-4.5.5/joda-time.jar  \n  inflating: stanford-corenlp-4.5.5/RESOURCE-LICENSES  \n  inflating: stanford-corenlp-4.5.5/jaxb-api-2.4.0-b180830.0359.jar  \n  inflating: stanford-corenlp-4.5.5/slf4j-simple.jar  \n  inflating: stanford-corenlp-4.5.5/build.xml  \n  inflating: stanford-corenlp-4.5.5/xom.jar  \n  inflating: stanford-corenlp-4.5.5/stanford-corenlp-4.5.5-sources.jar  \n  inflating: stanford-corenlp-4.5.5/LICENSE.txt  \n  inflating: stanford-corenlp-4.5.5/jaxb-impl-2.4.0-b180830.0438.jar  \n  inflating: stanford-corenlp-4.5.5/jollyday.jar  \n  inflating: stanford-corenlp-4.5.5/slf4j-api.jar  \n  inflating: stanford-corenlp-4.5.5/StanfordCoreNlpDemo.java  \n  inflating: stanford-corenlp-4.5.5/ejml-core-0.39-sources.jar  \n  inflating: stanford-corenlp-4.5.5/input.txt  \n  inflating: stanford-corenlp-4.5.5/stanford-corenlp-4.5.5-models.jar  \n  inflating: stanford-corenlp-4.5.5/StanfordDependenciesManual.pdf  \n  inflating: stanford-corenlp-4.5.5/SemgrexDemo.java  \n  inflating: stanford-corenlp-4.5.5/jollyday-0.4.9-sources.jar  \n  inflating: stanford-corenlp-4.5.5/input.txt.xml  \n  inflating: stanford-corenlp-4.5.5/README.txt  \n  inflating: stanford-corenlp-4.5.5/istack-commons-runtime-3.0.7.jar  \n   creating: stanford-corenlp-4.5.5/tokensregex/\n  inflating: stanford-corenlp-4.5.5/tokensregex/retokenize.txt  \n  inflating: stanford-corenlp-4.5.5/tokensregex/color.rules.txt  \n  inflating: stanford-corenlp-4.5.5/tokensregex/color.properties  \n  inflating: stanford-corenlp-4.5.5/tokensregex/color.input.txt  \n  inflating: stanford-corenlp-4.5.5/javax.activation-api-1.2.0-sources.jar  \n  inflating: stanford-corenlp-4.5.5/javax.json-api-1.0-sources.jar  \n  inflating: stanford-corenlp-4.5.5/ejml-simple-0.39-sources.jar  \n  inflating: stanford-corenlp-4.5.5/ejml-ddense-0.39-sources.jar  \n  inflating: stanford-corenlp-4.5.5/joda-time-2.10.5-sources.jar  \n  inflating: stanford-corenlp-4.5.5/ejml-core-0.39.jar  \n  inflating: stanford-corenlp-4.5.5/javax.json.jar  \n  inflating: stanford-corenlp-4.5.5/xom-1.3.9-sources.jar  \n  inflating: stanford-corenlp-4.5.5/input.txt.out  \n  inflating: stanford-corenlp-4.5.5/stanford-corenlp-4.5.5.jar  \n  inflating: stanford-corenlp-4.5.5/pom-java-11.xml  \n  inflating: stanford-corenlp-4.5.5/ejml-simple-0.39.jar  \n  inflating: stanford-corenlp-4.5.5/LIBRARY-LICENSES  \n  inflating: stanford-corenlp-4.5.5/jaxb-impl-2.4.0-b180830.0438-sources.jar  \n  inflating: stanford-corenlp-4.5.5/protobuf-java-3.19.6.jar  \n  inflating: stanford-corenlp-4.5.5/CoreNLP-to-HTML.xsl  \n  inflating: stanford-corenlp-4.5.5/corenlp.sh  \n  inflating: stanford-corenlp-4.5.5/istack-commons-runtime-3.0.7-sources.jar  \n  inflating: stanford-corenlp-4.5.5/ShiftReduceDemo.java  \n   creating: stanford-corenlp-4.5.5/patterns/\n extracting: stanford-corenlp-4.5.5/patterns/otherpeople.txt  \n  inflating: stanford-corenlp-4.5.5/patterns/stopwords.txt  \n  inflating: stanford-corenlp-4.5.5/patterns/example.properties  \n  inflating: stanford-corenlp-4.5.5/patterns/presidents.txt  \n  inflating: stanford-corenlp-4.5.5/patterns/goldnames.txt  \n  inflating: stanford-corenlp-4.5.5/patterns/names.txt  \n extracting: stanford-corenlp-4.5.5/patterns/goldplaces.txt  \n extracting: stanford-corenlp-4.5.5/patterns/places.txt  \n  inflating: stanford-corenlp-4.5.5/pom.xml  \n  inflating: stanford-corenlp-4.5.5/sample-project-pom.xml  \n  inflating: stanford-corenlp-4.5.5/stanford-corenlp-4.5.5-javadoc.jar  \n  inflating: stanford-corenlp-4.5.5/jaxb-api-2.4.0-b180830.0359-sources.jar  \n  inflating: stanford-corenlp-4.5.5/pom-java-17.xml  \n  inflating: stanford-corenlp-4.5.5/ejml-ddense-0.39.jar  \n","output_type":"stream"}]},{"cell_type":"code","source":"!wget http://nlp.stanford.edu/software/stanford-corenlp-4.5.5-models-english.jar","metadata":{"execution":{"iopub.status.busy":"2024-10-17T15:41:25.369426Z","iopub.execute_input":"2024-10-17T15:41:25.369891Z","iopub.status.idle":"2024-10-17T15:43:28.199352Z","shell.execute_reply.started":"2024-10-17T15:41:25.369843Z","shell.execute_reply":"2024-10-17T15:43:28.197672Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"--2024-10-17 15:41:26--  http://nlp.stanford.edu/software/stanford-corenlp-4.5.5-models-english.jar\nResolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\nConnecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://nlp.stanford.edu/software/stanford-corenlp-4.5.5-models-english.jar [following]\n--2024-10-17 15:41:26--  https://nlp.stanford.edu/software/stanford-corenlp-4.5.5-models-english.jar\nConnecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\nHTTP request sent, awaiting response... 302 FOUND\nLocation: https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-4.5.5-models-english.jar [following]\n--2024-10-17 15:41:26--  https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-4.5.5-models-english.jar\nResolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\nConnecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 444735210 (424M) [application/java-archive]\nSaving to: 'stanford-corenlp-4.5.5-models-english.jar'\n\nstanford-corenlp-4. 100%[===================>] 424.13M  4.31MB/s    in 2m 1s   \n\n2024-10-17 15:43:28 (3.49 MB/s) - 'stanford-corenlp-4.5.5-models-english.jar' saved [444735210/444735210]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!export CLASSPATH=$CLASSPATH:/kaggle/working/stanford-corenlp-4.5.5/*:/kaggle/working/stanford-corenlp-4.5.5-models-english.jar","metadata":{"execution":{"iopub.status.busy":"2024-10-17T15:43:28.203444Z","iopub.execute_input":"2024-10-17T15:43:28.203976Z","iopub.status.idle":"2024-10-17T15:43:29.399692Z","shell.execute_reply.started":"2024-10-17T15:43:28.203924Z","shell.execute_reply":"2024-10-17T15:43:29.397886Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import subprocess\n\ntry:\n    result = subprocess.run([\"jar\", \"tf\", \"/kaggle/working/stanford-corenlp-4.5.5/stanford-corenlp-4.5.5.jar\"], \n                            capture_output=True, text=True, check=True)\n    merge_nodes_entries = [line for line in result.stdout.split('\\n') if 'MergeNodes' in line]\n    \n    if merge_nodes_entries:\n        print(\"MergeNodes entries found:\")\n        for entry in merge_nodes_entries:\n            print(entry)\n    else:\n        print(\"No MergeNodes entries found in the JAR file.\")\nexcept subprocess.CalledProcessError as e:\n    print(f\"An error occurred while executing the jar command: {e}\")\nexcept FileNotFoundError:\n    print(\"The jar command was not found. Make sure Java is installed and in your PATH.\")","metadata":{"execution":{"iopub.status.busy":"2024-10-17T15:43:29.402127Z","iopub.execute_input":"2024-10-17T15:43:29.402695Z","iopub.status.idle":"2024-10-17T15:43:29.694494Z","shell.execute_reply.started":"2024-10-17T15:43:29.402640Z","shell.execute_reply":"2024-10-17T15:43:29.693001Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"MergeNodes entries found:\nedu/stanford/nlp/semgraph/semgrex/ssurgeon/MergeNodes.class\n","output_type":"stream"}]},{"cell_type":"code","source":"# Merge two words (\"ice\" and \"cream\") into a single compound noun (\"icecream\") within the dependency parse graph of the sentence: \"The child likes ice cream.\"\n# The program employs two methods: Ssurgeon MergeNodes and Manual Merge","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Attempts to merge \"ice\" and \"cream\" using Ssurgeon, alongside a manual merge for comparison.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test merging nodes using Ssurgeon\n# Adds a MergeNodes edit to the SsurgeonPattern without specifying additional attributes\n# Uses the execute method on the SsurgeonPattern\n# Takes the entire semantic graph as a parameter\n# Returns a Collection of SemanticGraph objects\n# Checks if the results collection is not empty, creates a new IndexedWord representing the expected merged node, verifies if this expected merged node exists in the resulting graph","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Semgrex pattern:\n# {}=gov: Matches any word in the sentence and labels it as the governor (gov). In the sentence \"The child likes ice cream.\", this would match the verb \"likes\"\n# >obj: Indicates that the governor (gov, i.e., \"likes\") has an object relation (obj) to another word\n# ({word:\" + nodesToMerge.get(1) + \"}=node1: Retrieves the second element from the nodesToMerge list, matches a word that's the object of the verb, and labels this matched word as \"node1\n# >compound {word:ice}=node2: Retrieves the first element from the nodesToMerge list, matches a word that's in a compound relationship with node1, and labels this matched word as \"node1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import subprocess\nimport os\n\njava_code = '''\n\nimport edu.stanford.nlp.pipeline.*;\nimport edu.stanford.nlp.semgraph.*;\nimport edu.stanford.nlp.semgraph.semgrex.*;\nimport edu.stanford.nlp.ling.*;\nimport edu.stanford.nlp.util.*;\nimport edu.stanford.nlp.trees.GrammaticalRelation;\nimport edu.stanford.nlp.semgraph.semgrex.ssurgeon.*;\n\nimport java.util.*;\n\npublic class SsurgeonMergeNodesComparison {\n\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.setProperty(\"annotators\", \"tokenize,ssplit,pos,lemma,depparse\");\n        StanfordCoreNLP pipeline = new StanfordCoreNLP(props);\n        \n        // Sentence where \"ice cream\" forms a compound noun\n        String text = \"The child likes ice cream.\";\n        \n        CoreDocument document = new CoreDocument(text);\n        pipeline.annotate(document);\n        \n        SemanticGraph originalGraph = document.sentences().get(0).dependencyParse();\n        \n        System.out.println(\"Original Dependency Graph:\");\n        System.out.println(originalGraph.toString(SemanticGraph.OutputFormat.LIST));\n\n        List<String> nodesToMerge = Arrays.asList(\"ice\", \"cream\");\n        \n        try {\n            // Clone the graph for both manual and Ssurgeon tests\n            SemanticGraph ssurgeonGraph = new SemanticGraph(originalGraph);\n            SemanticGraph manualGraph = new SemanticGraph(originalGraph);\n\n            testSsurgeonMergeNodes(ssurgeonGraph, nodesToMerge);\n            testManualMerge(manualGraph, nodesToMerge);\n            \n            System.out.println(\"Comparing results:\");\n            System.out.println(\"Ssurgeon MergeNodes result:\");\n            System.out.println(ssurgeonGraph.toString(SemanticGraph.OutputFormat.LIST));\n            System.out.println(\"Manual merge result:\");\n            System.out.println(manualGraph.toString(SemanticGraph.OutputFormat.LIST));\n            \n        } catch (Exception e) {\n            System.out.println(\"An error occurred: \" + e.getMessage());\n            e.printStackTrace();\n        }\n    }\n    \n    // Test merging nodes using Ssurgeon\n    \n    private static void testSsurgeonMergeNodes(SemanticGraph graph, List<String> nodesToMerge) {\n    System.out.println(\"Testing Ssurgeon MergeNodes:\");\n    \n    // Print the initial state of the graph before applying the merge\n    System.out.println(\"Graph before applying Ssurgeon MergeNodes:\");\n    System.out.println(graph.toString(SemanticGraph.OutputFormat.LIST));\n\n    // Create the Semgrex pattern to match the nodes\n    String patternString = \"{}=gov >obj ({word:\" + nodesToMerge.get(1) + \"}=node1 >compound {word:\" + nodesToMerge.get(0) + \"}=node2)\";\n    System.out.println(\"Semgrex Pattern: \" + patternString);\n    SemgrexPattern semgrexPattern = SemgrexPattern.compile(patternString);\n    \n    SemgrexMatcher matcher = semgrexPattern.matcher(graph);\n\n    // Check if the pattern is found and log the nodes involved\n    if (matcher.find()) {\n        IndexedWord gov = matcher.getNode(\"gov\");\n        IndexedWord node1 = matcher.getNode(\"node1\");  // \"cream\"\n        IndexedWord node2 = matcher.getNode(\"node2\");  // \"ice\"\n        \n        System.out.println(\"Match found:\");\n        System.out.println(\"Governor node: \" + gov);\n        System.out.println(\"Node1 (cream): \" + node1);\n        System.out.println(\"Node2 (ice): \" + node2);\n        \n        // Log the state of the graph before the merge\n        System.out.println(\"Graph state before Ssurgeon merge:\");\n        System.out.println(graph.toString(SemanticGraph.OutputFormat.LIST));\n\n        // Create the Ssurgeon edit for merging nodes\n        SsurgeonPattern surgeonPattern = new SsurgeonPattern(semgrexPattern);\n        SsurgeonEdit mergeNodesEdit = new MergeNodes(Arrays.asList(node1.word(), node2.word()), new HashMap<>());\n        surgeonPattern.addEdit(mergeNodesEdit);\n        \n        // Apply the Ssurgeon merge operation\n        Collection<SemanticGraph> results = surgeonPattern.execute(graph);\n        \n        // Log the state of the graph immediately after applying the merge\n        System.out.println(\"Graph after applying Ssurgeon MergeNodes (before cleanup):\");\n        System.out.println(graph.toString(SemanticGraph.OutputFormat.LIST));\n        \n        // Check if the graph was updated\n        if (results.isEmpty()) {\n            System.out.println(\"Ssurgeon MergeNodes failed to apply.\");\n        } else {\n            graph = results.iterator().next();\n            System.out.println(\"Ssurgeon MergeNodes applied successfully.\");\n        }\n\n        // Verify if the merged node is present in the graph\n        IndexedWord mergedNode = new IndexedWord(node1);\n        mergedNode.setWord(node1.word() + node2.word());\n        System.out.println(\"Merged node: \" + mergedNode);\n\n        if (graph.containsVertex(mergedNode)) {\n            System.out.println(\"Merged node '\" + mergedNode.word() + \"' is present in the graph.\");\n        } else {\n            System.out.println(\"Merged node '\" + mergedNode.word() + \"' is missing.\");\n        }\n\n        // Log the final state of the graph\n        System.out.println(\"Final graph after Ssurgeon merge and post-processing:\");\n        System.out.println(graph.toString(SemanticGraph.OutputFormat.LIST));\n    } else {\n        System.out.println(\"No match found for the pattern in Ssurgeon.\");\n    }\n}   \n    \n    // Test manual merge of nodes\n    \n    private static void testManualMerge(SemanticGraph graph, List<String> nodesToMerge) {\n    System.out.println(\"Testing Manual Merge:\");\n    String patternString = \"{}=gov >obj ({word:\" + nodesToMerge.get(1) + \"}=node1 >compound {word:\" + nodesToMerge.get(0) + \"}=node2)\";\n    System.out.println(\"Semgrex Pattern: \" + patternString);\n    SemgrexPattern semgrexPattern = SemgrexPattern.compile(patternString);\n    SemgrexMatcher matcher = semgrexPattern.matcher(graph);\n\n    if (matcher.find()) {\n        IndexedWord gov = matcher.getNode(\"gov\");\n        IndexedWord node1 = matcher.getNode(\"node1\");\n        IndexedWord node2 = matcher.getNode(\"node2\");\n\n        System.out.println(\"Current edges in the graph:\");\n        for (SemanticGraphEdge edge : graph.edgeListSorted()) {\n            System.out.println(edge);\n        }\n\n        // Create the new merged node with combined words \"ice\" and \"cream\"\n        IndexedWord mergedNode = new IndexedWord(node1);\n        mergedNode.setWord(node1.word() + node2.word());\n        mergedNode.setLemma(node1.lemma() + node2.lemma());\n        mergedNode.setTag(\"NN\");\n        mergedNode.setValue(node1.value() + node2.value());\n\n        // Add the merged node to the graph\n        graph.addVertex(mergedNode);\n\n        // Create a new edge between the governor and the merged node\n        SemanticGraphEdge newEdge = new SemanticGraphEdge(gov, mergedNode, GrammaticalRelation.valueOf(\"obj\"), 1.0, false);\n        graph.addEdge(newEdge);\n\n        // Transfer any edges from node1 or node2 to mergedNode (if there are other dependents)\n        for (SemanticGraphEdge edge : graph.getOutEdgesSorted(node1)) {\n            graph.addEdge(new SemanticGraphEdge(mergedNode, edge.getDependent(), edge.getRelation(), edge.getWeight(), edge.isExtra()));\n        }\n\n        for (SemanticGraphEdge edge : graph.getOutEdgesSorted(node2)) {\n            graph.addEdge(new SemanticGraphEdge(mergedNode, edge.getDependent(), edge.getRelation(), edge.getWeight(), edge.isExtra()));\n        }\n\n        // Print the graph state after adding the merged node and transferring dependencies\n        System.out.println(\"Graph after adding merged node and transferring dependencies:\");\n        System.out.println(graph.toString(SemanticGraph.OutputFormat.LIST));\n\n        // Disconnect the old nodes instead of removing them fully\n        graph.removeEdge(graph.getEdge(gov, node1));\n        graph.removeEdge(graph.getEdge(node1, node2));\n        \n        // Instead of removing the nodes, we mark them as inactive by setting their value to null\n        for (IndexedWord node : graph.vertexListSorted()) {\n            if (node.equals(node1) || node.equals(node2)) {\n                node.setValue(null);  // Mark as disconnected or inactive\n            }\n        }\n\n        // Check if merged node is retained after disconnection\n        if (graph.containsVertex(mergedNode)) {\n            System.out.println(\"Merged node 'creamice' is still in the graph.\");\n        } else {\n            System.out.println(\"Merged node 'creamice' is missing.\");\n        }\n\n        // Final graph check\n        System.out.println(\"Final graph after disconnecting old nodes:\");\n        System.out.println(graph.toString(SemanticGraph.OutputFormat.LIST));\n\n        System.out.println(\"Manual merge applied successfully.\");\n    } else {\n        System.out.println(\"No match found for manual merge.\");\n    }\n}\n\n}\n\n'''\n\nwith open('SsurgeonMergeNodesComparison.java', 'w') as f:\n    f.write(java_code)\n\n# Compile the Java code\ncompile_command = [\"javac\", \"-encoding\", \"UTF-8\", \"-cp\", \".:/kaggle/working/stanford-corenlp-4.5.5/*\", \"SsurgeonMergeNodesComparison.java\"]\ncompile_result = subprocess.run(compile_command, capture_output=True, text=True)\n\nif compile_result.returncode == 0:\n    print(\"Compilation successful\")\n    \n    # Run the Java program\n    run_command = [\"java\", \"-cp\", \".:/kaggle/working/stanford-corenlp-4.5.5/*\", \"SsurgeonMergeNodesComparison\"]\n    run_result = subprocess.run(run_command, capture_output=True, text=True)\n    \n    print(\"Program output:\")\n    print(run_result.stdout)\n    \n    if run_result.stderr:\n        print(\"Errors or warnings:\")\n        print(run_result.stderr)\nelse:\n    print(\"Compilation failed:\")\n    print(compile_result.stderr)","metadata":{"execution":{"iopub.status.busy":"2024-10-17T15:58:03.525598Z","iopub.execute_input":"2024-10-17T15:58:03.526815Z","iopub.status.idle":"2024-10-17T15:58:14.000597Z","shell.execute_reply.started":"2024-10-17T15:58:03.526725Z","shell.execute_reply":"2024-10-17T15:58:13.998891Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Compilation successful\nProgram output:\nOriginal Dependency Graph:\nroot(ROOT-0, likes-3)\ndet(child-2, The-1)\nnsubj(likes-3, child-2)\ncompound(cream-5, ice-4)\nobj(likes-3, cream-5)\npunct(likes-3, .-6)\n\nTesting Ssurgeon MergeNodes:\nGraph before applying Ssurgeon MergeNodes:\nroot(ROOT-0, likes-3)\ndet(child-2, The-1)\nnsubj(likes-3, child-2)\ncompound(cream-5, ice-4)\nobj(likes-3, cream-5)\npunct(likes-3, .-6)\n\nSemgrex Pattern: {}=gov >obj ({word:cream}=node1 >compound {word:ice}=node2)\nMatch found:\nGovernor node: likes/VBZ\nNode1 (cream): cream/NN\nNode2 (ice): ice/NN\nGraph state before Ssurgeon merge:\nroot(ROOT-0, likes-3)\ndet(child-2, The-1)\nnsubj(likes-3, child-2)\ncompound(cream-5, ice-4)\nobj(likes-3, cream-5)\npunct(likes-3, .-6)\n\nGraph after applying Ssurgeon MergeNodes (before cleanup):\nroot(ROOT-0, likes-3)\ndet(child-2, The-1)\nnsubj(likes-3, child-2)\ncompound(cream-5, ice-4)\nobj(likes-3, cream-5)\npunct(likes-3, .-6)\n\nSsurgeon MergeNodes applied successfully.\nMerged node: cream/NN\nMerged node 'creamice' is present in the graph.\nFinal graph after Ssurgeon merge and post-processing:\nroot(ROOT-0, likes-3)\ndet(child-2, The-1)\nnsubj(likes-3, child-2)\ncompound(cream-5, ice-4)\nobj(likes-3, cream-5)\npunct(likes-3, .-6)\n\nTesting Manual Merge:\nSemgrex Pattern: {}=gov >obj ({word:cream}=node1 >compound {word:ice}=node2)\nCurrent edges in the graph:\nchild/NN -> The/DT (det)\nlikes/VBZ -> child/NN (nsubj)\ncream/NN -> ice/NN (compound)\nlikes/VBZ -> cream/NN (obj)\nlikes/VBZ -> ./. (punct)\nGraph after adding merged node and transferring dependencies:\nroot(ROOT-0, likes-3)\ndet(child-2, The-1)\nnsubj(likes-3, child-2)\ncompound(cream-5, ice-4)\ncompound(creamice-5, ice-4)\nobj(likes-3, cream-5)\nobj(likes-3, creamice-5)\npunct(likes-3, .-6)\n\nMerged node 'creamice' is still in the graph.\nFinal graph after disconnecting old nodes:\nroot(ROOT-0, likes-3)\ndet(child-2, The-1)\nnsubj(likes-3, child-2)\ncompound(creamice-5, null-4)\nobj(likes-3, creamice-5)\npunct(likes-3, .-6)\n\nManual merge applied successfully.\nComparing results:\nSsurgeon MergeNodes result:\nroot(ROOT-0, likes-3)\ndet(child-2, The-1)\nnsubj(likes-3, child-2)\ncompound(null-5, null-4)\nobj(likes-3, null-5)\npunct(likes-3, .-6)\n\nManual merge result:\nroot(ROOT-0, likes-3)\ndet(child-2, The-1)\nnsubj(likes-3, child-2)\ncompound(creamice-5, null-4)\nobj(likes-3, creamice-5)\npunct(likes-3, .-6)\n\n\nErrors or warnings:\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words-distsim.tagger ... done [1.3 sec].\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... Time elapsed: 2.2 sec\n[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 20000 vectors, elapsed Time: 1.896 sec\n[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [4.1 sec].\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#Key observations:\n# The original dependency graph correctly represents the sentence structure\n# The Semgrex pattern successfully matches the target nodes (\"ice\" and \"cream\")\n# The Ssurgeon MergeNodes operation reports to be applied successfully\n# Despite this, the graph structure remains unchanged after Ssurgeon MergeNodes\n# The manual merge successfully creates a new \"creamice\" node\n# The manual merge method properly disconnects the old nodes\n# The final graphs for Ssurgeon and manual merges are different","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inferences from the Output:\n# The Ssurgeon method seems to preserve all existing edges, even after claiming to merge nodes\n# Despite the MergeNodes operation, the original nodes (\"ice\" and \"cream\") persist in the graph\n# The appearance of \"null\" nodes in both Ssurgeon and manual merge results indicates a potential issue with node removal or deactivation in the graph structure","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SsurgeonMergeNodes: Attempts to merge \"ice\" and \"cream\" using Ssurgeon\n# Sets the \"pos\" (part of speech) to \"NN\" (noun) for the merged word\n# Uses the evaluate method to apply the merge operation directly\n# Takes the graph and a SemgrexMatcher as parameters\n# Returns a boolean indicating whether the merge was successful","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Semgrex pattern:\n# {}=gov: Matches any word in the sentence and labels it as the governor (gov). In the sentence \"The child likes ice cream.\", this would match the verb \"likes\".\n# >obj: Indicates that the governor (gov, i.e., \"likes\") has an object relation (obj) to another word.\n# {word:cream}=node1: Matches the word \"cream\" and labels it as node1.\n# >compound {word:ice}=node2: Indicates that node1 (\"cream\") has a compound relation (compound) to the word \"ice\", labeled as node2.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import subprocess\nimport os\n\njava_code = '''\nimport edu.stanford.nlp.pipeline.*;\nimport edu.stanford.nlp.semgraph.*;\nimport edu.stanford.nlp.semgraph.semgrex.*;\nimport edu.stanford.nlp.ling.*;\nimport edu.stanford.nlp.util.*;\nimport edu.stanford.nlp.semgraph.semgrex.ssurgeon.*;\n\nimport java.util.*;\n\npublic class SsurgeonMergeNodes {\n\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.setProperty(\"annotators\", \"tokenize,ssplit,pos,lemma,depparse\");\n        StanfordCoreNLP pipeline = new StanfordCoreNLP(props);\n        \n        String text = \"The child likes ice cream.\";\n        \n        CoreDocument document = new CoreDocument(text);\n        pipeline.annotate(document);\n        \n        SemanticGraph graph = document.sentences().get(0).dependencyParse();\n        \n        System.out.println(\"Original Dependency Graph:\");\n        System.out.println(graph.toString(SemanticGraph.OutputFormat.LIST));\n\n        testSsurgeonMergeNodes(graph);\n    }\n    \n    private static void testSsurgeonMergeNodes(SemanticGraph graph) {\n        System.out.println(\"Testing Ssurgeon MergeNodes:\");\n        \n        String patternString = \"{}=gov >obj ({word:cream}=node1 >compound {word:ice}=node2)\";\n        System.out.println(\"Semgrex Pattern: \" + patternString);\n        SemgrexPattern semgrexPattern = SemgrexPattern.compile(patternString);\n        \n        SemgrexMatcher matcher = semgrexPattern.matcher(graph);\n\n        if (matcher.find()) {\n            IndexedWord gov = matcher.getNode(\"gov\");\n            IndexedWord node1 = matcher.getNode(\"node1\");  // \"cream\"\n            IndexedWord node2 = matcher.getNode(\"node2\");  // \"ice\"\n            \n            System.out.println(\"Match found:\");\n            System.out.println(\"Governor node: \" + gov);\n            System.out.println(\"Node1 (cream): \" + node1);\n            System.out.println(\"Node2 (ice): \" + node2);\n\n            // Create the Ssurgeon edit for merging nodes\n            SsurgeonPattern surgeonPattern = new SsurgeonPattern(semgrexPattern);\n            Map<String, String> attributes = new HashMap<>();\n            attributes.put(\"pos\", \"NN\");\n            SsurgeonEdit mergeNodesEdit = new MergeNodes(Arrays.asList(node1.word(), node2.word()), attributes);\n            surgeonPattern.addEdit(mergeNodesEdit);\n            \n            // Apply the Ssurgeon merge operation\n            boolean editApplied = mergeNodesEdit.evaluate(graph, matcher);\n            \n            System.out.println(\"Ssurgeon MergeNodes edit applied: \" + editApplied);\n            \n            System.out.println(\"Graph after applying Ssurgeon MergeNodes:\");\n            System.out.println(graph.toString(SemanticGraph.OutputFormat.LIST));\n            \n            // Check for the merged node\n            IndexedWord mergedNode = graph.getNodeByIndex(node1.index());\n            if (mergedNode != null && mergedNode.word().equals(node1.word() + node2.word())) {\n                System.out.println(\"Merged node '\" + mergedNode.word() + \"' is present in the graph.\");\n                System.out.println(\"Merged node details: \" + mergedNode);\n                \n                System.out.println(\"Edges of the merged node:\");\n                for (SemanticGraphEdge edge : graph.outgoingEdgeList(mergedNode)) {\n                    System.out.println(\"Outgoing: \" + edge);\n                }\n                for (SemanticGraphEdge edge : graph.incomingEdgeList(mergedNode)) {\n                    System.out.println(\"Incoming: \" + edge);\n                }\n            } else {\n                System.out.println(\"Merged node '\" + node1.word() + node2.word() + \"' is missing or incorrect.\");\n                System.out.println(\"Node at index \" + node1.index() + \": \" + mergedNode);\n            }\n\n        } else {\n            System.out.println(\"No match found for the pattern in Ssurgeon.\");\n        }\n    }\n}\n\n'''\n\nwith open('SsurgeonMergeNodes.java', 'w') as f:\n    f.write(java_code)\n\n# Compile the Java code\ncompile_command = [\"javac\", \"-encoding\", \"UTF-8\", \"-cp\", \".:/kaggle/working/stanford-corenlp-4.5.5/*\", \"SsurgeonMergeNodes.java\"]\ncompile_result = subprocess.run(compile_command, capture_output=True, text=True)\n\nif compile_result.returncode == 0:\n    print(\"Compilation successful\")\n    \n    # Run the Java program\n    run_command = [\"java\", \"-cp\", \".:/kaggle/working/stanford-corenlp-4.5.5/*\", \"SsurgeonMergeNodes\"]\n    run_result = subprocess.run(run_command, capture_output=True, text=True)\n    \n    print(\"Program output:\")\n    print(run_result.stdout)\n    \n    if run_result.stderr:\n        print(\"Errors or warnings:\")\n        print(run_result.stderr)\nelse:\n    print(\"Compilation failed:\")\n    print(compile_result.stderr)","metadata":{"execution":{"iopub.status.busy":"2024-10-17T16:17:04.575878Z","iopub.execute_input":"2024-10-17T16:17:04.577193Z","iopub.status.idle":"2024-10-17T16:17:13.294690Z","shell.execute_reply.started":"2024-10-17T16:17:04.577115Z","shell.execute_reply":"2024-10-17T16:17:13.293135Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Compilation successful\nProgram output:\nOriginal Dependency Graph:\nroot(ROOT-0, likes-3)\ndet(child-2, The-1)\nnsubj(likes-3, child-2)\ncompound(cream-5, ice-4)\nobj(likes-3, cream-5)\npunct(likes-3, .-6)\n\nTesting Ssurgeon MergeNodes:\nSemgrex Pattern: {}=gov >obj ({word:cream}=node1 >compound {word:ice}=node2)\nMatch found:\nGovernor node: likes/VBZ\nNode1 (cream): cream/NN\nNode2 (ice): ice/NN\nSsurgeon MergeNodes edit applied: false\nGraph after applying Ssurgeon MergeNodes:\nroot(ROOT-0, likes-3)\ndet(child-2, The-1)\nnsubj(likes-3, child-2)\ncompound(cream-5, ice-4)\nobj(likes-3, cream-5)\npunct(likes-3, .-6)\n\nMerged node 'creamice' is missing or incorrect.\nNode at index 5: cream/NN\n\nErrors or warnings:\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words-distsim.tagger ... done [1.4 sec].\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... Time elapsed: 2.5 sec\n[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 20000 vectors, elapsed Time: 1.878 sec\n[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [4.4 sec].\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Key Observations:\n# The original dependency graph correctly represents the sentence \"The child likes ice cream.\"\n# The Semgrex pattern successfully matches the compound noun structure \"ice cream\" in the sentence.\n# The MergeNodes operation reports that it was not applied successfully (editApplied: false).\n# The dependency graph remains unchanged after the attempted MergeNodes operation.\n# The program fails to find a merged node 'creamice' in the graph.\n# The node at index 5 remains as \"cream/NN\", indicating no merging occurred.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Key Inferences:\n# The Ssurgeon MergeNodes operation is not functioning as expected, despite correctly identifying the nodes to be merged.","metadata":{},"execution_count":null,"outputs":[]}]}